{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 59093,
          "databundleVersionId": 7469972,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "EEG_Model_Final_Amulya",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmulyaMat/EEG-Signal-Seizure-Detection/blob/main/EEG_Model_Final_Amulya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'hms-harmful-brain-activity-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F59093%2F7469972%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240401%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240401T023013Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D15071ecb525e95669e7b8e7567f9ed0b64f26474242798b0c825392121d6c87ac24e62cd1164157520fc0f8b103cd5e250e6aedbaa237e23fdf265d65ab11dd7c3e8adf7783dc5b0fefdaf6459c47f5aa44341b0fab0785d781edd47637c5e91019b3db5585d109bf5a30251ead29f4cbb71758b28214040c15a35e874ea557c64cb3f071da84b0152e5d4ddd809f22efef789a7f8da7e21c518853e028ca2f3ae4db8fa169ec0e4f79fef4b015419ed31cb4644168735d0f074ea3c967d0ec548d9f2fa4e68b3c5099105495da83425cf3321da05dffcd7f46803b682570f241458330ad5f96d537d17e01b74d1f533eb543b4620c95277bedf5cd93ad11fff'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "wH_y4jd2fjVT"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importing libraries"
      ],
      "metadata": {
        "id": "e-5wFMjofjVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:41.843284Z",
          "iopub.execute_input": "2024-03-28T17:09:41.844253Z",
          "iopub.status.idle": "2024-03-28T17:09:47.850426Z",
          "shell.execute_reply.started": "2024-03-28T17:09:41.844199Z",
          "shell.execute_reply": "2024-03-28T17:09:47.848199Z"
        },
        "trusted": true,
        "id": "OJnYtH26fjVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Importing EEG data (train.csv) and extracting 10 second secgments"
      ],
      "metadata": {
        "id": "C__hy_82fjVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n",
        "print('Train shape', train.shape )\n",
        "train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:47.853261Z",
          "iopub.execute_input": "2024-03-28T17:09:47.853858Z",
          "iopub.status.idle": "2024-03-28T17:09:48.274077Z",
          "shell.execute_reply.started": "2024-03-28T17:09:47.853824Z",
          "shell.execute_reply": "2024-03-28T17:09:48.272924Z"
        },
        "trusted": true,
        "id": "kH7o9AKZfjVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = train.eeg_id.unique()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:48.275675Z",
          "iopub.execute_input": "2024-03-28T17:09:48.276466Z",
          "iopub.status.idle": "2024-03-28T17:09:48.291201Z",
          "shell.execute_reply.started": "2024-03-28T17:09:48.276407Z",
          "shell.execute_reply": "2024-03-28T17:09:48.289795Z"
        },
        "trusted": true,
        "id": "p1UFwDq0fjVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "n = 10\n",
        "sample_ids = random.sample(list(ids), n)\n",
        "sample_ids"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:48.294465Z",
          "iopub.execute_input": "2024-03-28T17:09:48.294856Z",
          "iopub.status.idle": "2024-03-28T17:09:48.308846Z",
          "shell.execute_reply.started": "2024-03-28T17:09:48.294824Z",
          "shell.execute_reply": "2024-03-28T17:09:48.307338Z"
        },
        "trusted": true,
        "id": "yHSFMFYufjVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING DATA LOADER FOR SPECIFIC EEG IDS\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def create_data_loader(eeg_ids, eeg_data_dir, train_data, segment_length=10):\n",
        "    \"\"\"\n",
        "    Create a data loader function to extract 10-second EEG segments for specified EEG IDs.\n",
        "\n",
        "    Args:\n",
        "    - eeg_ids (list): List of EEG IDs for which segments need to be extracted.\n",
        "    - eeg_data_dir (str): Directory path where EEG data files are stored.\n",
        "    - train_data (DataFrame): DataFrame containing training data with EEG labels and offsets.\n",
        "    - segment_length (int): Length of EEG segments in seconds.\n",
        "\n",
        "    Returns:\n",
        "    - data_loader (generator): Generator function to yield EEG segments along with target labels.\n",
        "    \"\"\"\n",
        "    def data_loader():\n",
        "        for eeg_id in eeg_ids:\n",
        "            # Load EEG data for the current EEG ID\n",
        "            eeg_data_path = f\"{eeg_data_dir}/{eeg_id}.parquet\"\n",
        "            example = pd.read_parquet(eeg_data_path)\n",
        "\n",
        "            # Filter training data for the current EEG ID\n",
        "            train_eegid = train_data[train_data['eeg_id'] == eeg_id]\n",
        "            offset_values_list = train_eegid['eeg_label_offset_seconds'].tolist()\n",
        "            print(\"Number of offset subsamples for EEG ID\", eeg_id, \":\", len(offset_values_list))\n",
        "\n",
        "            # Extract 10-second EEG segments along with target labels\n",
        "            for offset in offset_values_list:\n",
        "                start_index = int(offset) * 200\n",
        "                end_index = start_index + (segment_length * 200)\n",
        "\n",
        "                # Extract 10-second segment centered around the offset\n",
        "                middle_index = (start_index + end_index) // 2\n",
        "                segment_start = middle_index - (segment_length // 2 * 200)\n",
        "                segment_end = middle_index + (segment_length // 2 * 200)\n",
        "\n",
        "                # Extract EEG segment\n",
        "                eeg_segment = example.iloc[segment_start:segment_end].reset_index(drop=True)\n",
        "\n",
        "                # Get target labels\n",
        "                target_labels = train_eegid.iloc[0][['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n",
        "\n",
        "                # Yield EEG segment along with target labels\n",
        "                yield eeg_segment, target_labels\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "# Example usage:\n",
        "eeg_ids = sample_ids\n",
        "eeg_data_dir = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs\"\n",
        "train_data = train  # Assuming 'train' is your DataFrame containing training data\n",
        "segment_length = 10  # 10-second EEG segments\n",
        "loader = create_data_loader(eeg_ids, eeg_data_dir, train_data, segment_length)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:48.31079Z",
          "iopub.execute_input": "2024-03-28T17:09:48.311248Z",
          "iopub.status.idle": "2024-03-28T17:09:48.325941Z",
          "shell.execute_reply.started": "2024-03-28T17:09:48.311218Z",
          "shell.execute_reply": "2024-03-28T17:09:48.324241Z"
        },
        "trusted": true,
        "id": "VTwfXPetfjVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting EEG data and target data from data loader\n",
        "\n",
        "# Collect all EEG segments and target labels into separate lists\n",
        "all_segments = []\n",
        "all_targets = []\n",
        "\n",
        "# Iterate through the data loader to extract EEG segments and target labels\n",
        "for eeg_segment, target_labels in loader():\n",
        "    # Append each EEG segment to the list\n",
        "    all_segments.append(eeg_segment)\n",
        "    # Append corresponding target labels to the list\n",
        "    all_targets.append(target_labels)\n",
        "\n",
        "# Concatenate all segments into a single DataFrame\n",
        "full_eeg_segments = pd.concat(all_segments, ignore_index=True)\n",
        "full_eeg_segments"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:48.328158Z",
          "iopub.execute_input": "2024-03-28T17:09:48.328655Z",
          "iopub.status.idle": "2024-03-28T17:09:48.999416Z",
          "shell.execute_reply.started": "2024-03-28T17:09:48.328614Z",
          "shell.execute_reply": "2024-03-28T17:09:48.997914Z"
        },
        "trusted": true,
        "id": "xChwp3gKfjVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_eeg_targets = pd.DataFrame(all_targets)\n",
        "full_eeg_targets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:49.001806Z",
          "iopub.execute_input": "2024-03-28T17:09:49.003196Z",
          "iopub.status.idle": "2024-03-28T17:09:49.030102Z",
          "shell.execute_reply.started": "2024-03-28T17:09:49.003153Z",
          "shell.execute_reply": "2024-03-28T17:09:49.029127Z"
        },
        "trusted": true,
        "id": "DN9MBhL7fjVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Visualizing EEG signals"
      ],
      "metadata": {
        "id": "wDLV7l0DfjVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_eeg(df, title):\n",
        "    fig, axs = plt.subplots(20, 1, figsize=(30, 20), sharex=True)\n",
        "\n",
        "    for i, ax in enumerate(axs):\n",
        "        ax.plot(df.iloc[:,i], color=\"black\")\n",
        "        ax.set_ylabel(df.columns[i], rotation=0)\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_xticks([])\n",
        "        ax.spines[[\"top\", \"bottom\", \"left\", \"right\"]].set_visible(False)\n",
        "\n",
        "    fig.suptitle(title, fontsize=50, verticalalignment='top')\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust the layout to not overlap with the figure title\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:58.725981Z",
          "iopub.execute_input": "2024-03-28T17:09:58.727499Z",
          "iopub.status.idle": "2024-03-28T17:09:58.73745Z",
          "shell.execute_reply.started": "2024-03-28T17:09:58.727452Z",
          "shell.execute_reply": "2024-03-28T17:09:58.73588Z"
        },
        "trusted": true,
        "id": "vJ3ZszUGfjVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_example = pd.read_parquet('/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/941668605.parquet')\n",
        "print(f'eeg_id=941668605 has {eeg_example.shape[0]} samples.')\n",
        "print()\n",
        "display(eeg_example)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:59.050465Z",
          "iopub.execute_input": "2024-03-28T17:09:59.050936Z",
          "iopub.status.idle": "2024-03-28T17:09:59.117335Z",
          "shell.execute_reply.started": "2024-03-28T17:09:59.050903Z",
          "shell.execute_reply": "2024-03-28T17:09:59.116137Z"
        },
        "trusted": true,
        "id": "KcHe36oWfjVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_eeg(eeg_example, 'EEG signal, id = 941668605, all subsamples')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:09:59.674957Z",
          "iopub.execute_input": "2024-03-28T17:09:59.675692Z",
          "iopub.status.idle": "2024-03-28T17:10:02.740174Z",
          "shell.execute_reply.started": "2024-03-28T17:09:59.675647Z",
          "shell.execute_reply": "2024-03-28T17:10:02.738203Z"
        },
        "trusted": true,
        "id": "k3swuEXmfjVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offset = 0\n",
        "start_index = int(offset) * 200\n",
        "end_index = start_index + (segment_length * 200)\n",
        "\n",
        "# Extract 10-second segment centered around the offset\n",
        "middle_index = (start_index + end_index) // 2\n",
        "segment_start = middle_index - (segment_length // 2 * 200)\n",
        "segment_end = middle_index + (segment_length // 2 * 200)\n",
        "\n",
        "# Extract EEG segment\n",
        "eeg_segment_0 = eeg_example.iloc[segment_start:segment_end].reset_index(drop=True)\n",
        "\n",
        "# Get target labels\n",
        "#target_labels = train_eegid.iloc[0][['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n",
        "\n",
        "eeg_segment_0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:10:02.742141Z",
          "iopub.execute_input": "2024-03-28T17:10:02.742745Z",
          "iopub.status.idle": "2024-03-28T17:10:02.789326Z",
          "shell.execute_reply.started": "2024-03-28T17:10:02.742712Z",
          "shell.execute_reply": "2024-03-28T17:10:02.787875Z"
        },
        "trusted": true,
        "id": "178wKpDkfjVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_eeg(eeg_segment_0, 'EEG signal, id = 941668605, subsamples = 0')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:10:02.790907Z",
          "iopub.execute_input": "2024-03-28T17:10:02.791324Z",
          "iopub.status.idle": "2024-03-28T17:10:05.55209Z",
          "shell.execute_reply.started": "2024-03-28T17:10:02.79129Z",
          "shell.execute_reply": "2024-03-28T17:10:05.550255Z"
        },
        "trusted": true,
        "id": "u87w9GNnfjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(2000), eeg_segment_0.iloc[:,0], color=\"blue\")\n",
        "plt.xlabel(\"# of samples\")\n",
        "plt.ylabel(\"voltage mV\")\n",
        "plt.title('EEG Signal, Fp1')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:10:05.554138Z",
          "iopub.execute_input": "2024-03-28T17:10:05.554934Z",
          "iopub.status.idle": "2024-03-28T17:10:05.938926Z",
          "shell.execute_reply.started": "2024-03-28T17:10:05.5549Z",
          "shell.execute_reply": "2024-03-28T17:10:05.937526Z"
        },
        "trusted": true,
        "id": "3k6TC7aIfjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_eeg_segments"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:10:05.940474Z",
          "iopub.execute_input": "2024-03-28T17:10:05.940859Z",
          "iopub.status.idle": "2024-03-28T17:10:05.979906Z",
          "shell.execute_reply.started": "2024-03-28T17:10:05.940828Z",
          "shell.execute_reply": "2024-03-28T17:10:05.978349Z"
        },
        "trusted": true,
        "id": "u272sXWafjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Feature Engineering"
      ],
      "metadata": {
        "id": "8LEc1Oy-fjVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3a. Denoising signals with wavelet transform"
      ],
      "metadata": {
        "id": "nzRnRYD6fjVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# denoising function using wavelet transform\n",
        "import pywt\n",
        "\n",
        "def maddest(d, axis=None):\n",
        "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
        "\n",
        "def denoise(x, wavelet='haar', level=1):\n",
        "    ret = {key:[] for key in x.columns}\n",
        "\n",
        "    for pos in x.columns:\n",
        "        coeff = pywt.wavedec(x[pos], wavelet, mode=\"per\")\n",
        "        sigma = (1/0.6745) * maddest(coeff[-level])\n",
        "\n",
        "        uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
        "        coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
        "\n",
        "        ret[pos]=pywt.waverec(coeff, wavelet, mode='per')\n",
        "\n",
        "    return pd.DataFrame(ret)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:10:05.981823Z",
          "iopub.execute_input": "2024-03-28T17:10:05.98234Z",
          "iopub.status.idle": "2024-03-28T17:10:06.609723Z",
          "shell.execute_reply.started": "2024-03-28T17:10:05.982304Z",
          "shell.execute_reply": "2024-03-28T17:10:06.608441Z"
        },
        "trusted": true,
        "id": "ZQlEFpMzfjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_segment_0_denoised = denoise(eeg_segment_0, wavelet=\"db8\")\n",
        "plot_eeg(eeg_segment_0_denoised, 'Denoised EEG signals for EEG id =  941668605, offset = 0')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:10:08.390579Z",
          "iopub.execute_input": "2024-03-28T17:10:08.391602Z",
          "iopub.status.idle": "2024-03-28T17:10:10.770363Z",
          "shell.execute_reply.started": "2024-03-28T17:10:08.391552Z",
          "shell.execute_reply": "2024-03-28T17:10:10.76914Z"
        },
        "trusted": true,
        "id": "cx2Zx2TTfjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(2000), eeg_segment_0_denoised.iloc[:,0], color=\"blue\")\n",
        "plt.xlabel(\"# of samples\")\n",
        "plt.ylabel(\"voltage mV\")\n",
        "plt.title('EEG Signal, Fp1')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:10:16.794162Z",
          "iopub.execute_input": "2024-03-28T17:10:16.794605Z",
          "iopub.status.idle": "2024-03-28T17:10:17.190981Z",
          "shell.execute_reply.started": "2024-03-28T17:10:16.794572Z",
          "shell.execute_reply": "2024-03-28T17:10:17.189577Z"
        },
        "trusted": true,
        "id": "xNI86uScfjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoise entire data\n",
        "full_eeg_segments_denoised = denoise(full_eeg_segments, wavelet=\"db8\")\n",
        "full_eeg_segments_denoised"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:10:21.300007Z",
          "iopub.execute_input": "2024-03-28T17:10:21.301145Z",
          "iopub.status.idle": "2024-03-28T17:10:21.435712Z",
          "shell.execute_reply.started": "2024-03-28T17:10:21.301077Z",
          "shell.execute_reply": "2024-03-28T17:10:21.434121Z"
        },
        "trusted": true,
        "id": "6PDoJe5QfjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3b. Discrete wavelet transform features"
      ],
      "metadata": {
        "id": "p7SEQxW7fjVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pywt import wavedec\n",
        "\n",
        "def wavelet_decompose_channels(data, level, output=False):\n",
        "  # take every x number of points using numpy's slicing (start:stop:step)\n",
        "    data = data[0::2]\n",
        "\n",
        "    data.columns.name='channel'\n",
        "\n",
        "    # transpose the data\n",
        "    data_t = data.transpose()\n",
        "\n",
        "    # get the wavelet coefficients at each level in a list\n",
        "    coeffs_list = wavedec(data_t.values, wavelet='db4', level=level)\n",
        "    #print(len(coeffs_list))\n",
        "\n",
        "    # make a list of the component names (later column rows)\n",
        "    nums = list(range(1,level+1))\n",
        "    names=[]\n",
        "    for num in nums:\n",
        "        names.append('D' + str(num))\n",
        "    names.append('A' + str(nums[-1]))\n",
        "\n",
        "  # reverse the names so it counts down\n",
        "    names = names[::-1]\n",
        "    #print(names)\n",
        "\n",
        "    i = 0\n",
        "    wavelets = pd.DataFrame()\n",
        "    for i in range(1, len(coeffs_list)):\n",
        "    #for i, array in enumerate(coeffs_list):\n",
        "        #print(i)\n",
        "        array = coeffs_list[i]\n",
        "        # turn into a dataframe and transpose\n",
        "        level_df = pd.DataFrame(array)\n",
        "        level_df.index = data.columns\n",
        "        level_df['level'] = names[i]\n",
        "        level_df= level_df.set_index('level', append=True)\n",
        "        level_df=level_df.T\n",
        "        # add the next levels df to another column\n",
        "        wavelets = pd.concat([wavelets,level_df], axis=1, sort=True)\n",
        "\n",
        "    # sort values along the channels\n",
        "    wavelets = wavelets.sort_values(['channel', 'level'], axis=1)\n",
        "\n",
        "  # remove the AN levels\n",
        "  #regex = re.compile('D')\n",
        "  #bad_items = [x for x in list(wavelets.columns.levels[1]) if not regex.match(x)]\n",
        "  #decom_wavelets = wavelets.drop(bad_items, axis=1, level = 'level')\n",
        "\n",
        "  #decom_wavelets.index.name='sample'\n",
        "\n",
        "  #if output:\n",
        "  #  display(decom_wavelets.head())\n",
        "\n",
        "    wavelets_cleaned = wavelets.dropna()\n",
        "\n",
        "    return wavelets_cleaned\n",
        "\n",
        "dwt_wavelets = wavelet_decompose_channels(full_eeg_segments_denoised, level=5, output=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:13:41.216852Z",
          "iopub.execute_input": "2024-03-28T17:13:41.217346Z",
          "iopub.status.idle": "2024-03-28T17:13:41.378954Z",
          "shell.execute_reply.started": "2024-03-28T17:13:41.217314Z",
          "shell.execute_reply": "2024-03-28T17:13:41.377287Z"
        },
        "trusted": true,
        "id": "KkLN-p60fjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dwt_wavelets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:13:41.600181Z",
          "iopub.execute_input": "2024-03-28T17:13:41.6018Z",
          "iopub.status.idle": "2024-03-28T17:13:41.653863Z",
          "shell.execute_reply.started": "2024-03-28T17:13:41.601736Z",
          "shell.execute_reply": "2024-03-28T17:13:41.652244Z"
        },
        "trusted": true,
        "id": "KbK_A1eufjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c. Finding statistics for DWT features"
      ],
      "metadata": {
        "id": "FQb1VPcUfjVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log Sum"
      ],
      "metadata": {
        "id": "OxuL9seRfjVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minus_small(data):\n",
        "  # find the smallest value for each data column (channel)...\n",
        "  min_val = data.min()\n",
        "  # ...and subtract it from all the data in the column and add one\n",
        "  data = data.subtract(min_val).add(1)\n",
        "\n",
        "  return data\n",
        "\n",
        "def log_sum(data, output=False):\n",
        "    absolute_sums = data.sum()\n",
        "    # ...and subtract it from all the data in the column and add one\n",
        "    absolute_sums_minus = minus_small(absolute_sums)\n",
        "    # find the log of each elecment (datapoint)\n",
        "    absolute_sums_log = absolute_sums_minus.apply(np.log)\n",
        "    absolute_sums_log.index += '_LSWT'\n",
        "\n",
        "    if output:\n",
        "        display(absolute_sums_log)\n",
        "\n",
        "    return absolute_sums_log\n",
        "\n",
        "\n",
        "def reformat(data, feature_name):\n",
        "  data.index = [feature_name+level for level in data.index]\n",
        "  data.index.name = 'feature'\n",
        "  data = pd.DataFrame(data.unstack()).T\n",
        "\n",
        "  return data\n",
        "\n",
        "def log_sum_channels(data, output=False):\n",
        "  #absolute_sums = data.sum()\n",
        "  # make the columns channels\n",
        "  #absolute_sums = absolute_sums.unstack('channel')\n",
        "  # for each channel apply the minus small function\n",
        "\n",
        "    logsum = pd.DataFrame(index=data.index)\n",
        "\n",
        "    # Iterate over each channel and calculate the mean across 'D1' to 'D5'\n",
        "    for channel in data.columns.get_level_values(0).unique():\n",
        "        print(channel)\n",
        "    # Calculate the mean for the current channel\n",
        "\n",
        "        logsum[channel] = data[channel].apply(minus_small)\n",
        "        logsum[channel] = data[channel].apply(np.log)\n",
        "\n",
        "\n",
        "    logsum.columns = [f\"{col}_LSTW\" for col in logsum.columns]\n",
        "\n",
        "\n",
        "    return logsum"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:39:53.848339Z",
          "iopub.execute_input": "2024-03-28T17:39:53.848858Z",
          "iopub.status.idle": "2024-03-28T17:39:53.863189Z",
          "shell.execute_reply.started": "2024-03-28T17:39:53.848826Z",
          "shell.execute_reply": "2024-03-28T17:39:53.861373Z"
        },
        "trusted": true,
        "id": "EqqVmNiifjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_sum_channels(dwt_wavelets, output=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T17:39:55.229092Z",
          "iopub.execute_input": "2024-03-28T17:39:55.229522Z",
          "iopub.status.idle": "2024-03-28T17:39:55.310002Z",
          "shell.execute_reply.started": "2024-03-28T17:39:55.229493Z",
          "shell.execute_reply": "2024-03-28T17:39:55.308063Z"
        },
        "trusted": true,
        "id": "scJQajeqfjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ave(data, output=False):\n",
        "    # Initialize an empty DataFrame to store the means for each channel\n",
        "    means = pd.DataFrame(index=example_wavelets.index)\n",
        "\n",
        "    # Iterate over each channel and calculate the mean across 'D1' to 'D5'\n",
        "    for channel in data.columns.get_level_values(0).unique():\n",
        "    # Calculate the mean for the current channel\n",
        "        means[channel] = data[channel].mean(axis=1)\n",
        "\n",
        "    means.columns = [f\"{col}_DT_mean\" for col in means.columns]\n",
        "\n",
        "    return means\n",
        "\n",
        "\n",
        "# Use the function with your data\n",
        "example_wavelet_mean = ave(example_wavelets, output=True)\n",
        "example_wavelet_mean"
      ],
      "metadata": {
        "id": "u0YCx_F5fjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean"
      ],
      "metadata": {
        "id": "Fd6W2it_fjVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ave(data, output=False):\n",
        "    # Initialize an empty DataFrame to store the means for each channel\n",
        "    means = pd.DataFrame(index=example_wavelets.index)\n",
        "\n",
        "    # Iterate over each channel and calculate the mean across 'D1' to 'D5'\n",
        "    for channel in data.columns.get_level_values(0).unique():\n",
        "    # Calculate the mean for the current channel\n",
        "        means[channel] = data[channel].mean(axis=1)\n",
        "\n",
        "    means.columns = [f\"{col}_DT_mean\" for col in means.columns]\n",
        "\n",
        "    return means\n",
        "\n",
        "\n",
        "# Use the function with your data\n",
        "example_wavelet_mean = ave(example_wavelets, output=True)\n",
        "example_wavelet_mean"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T07:19:56.427389Z",
          "iopub.execute_input": "2024-03-28T07:19:56.427728Z",
          "iopub.status.idle": "2024-03-28T07:19:56.481422Z",
          "shell.execute_reply.started": "2024-03-28T07:19:56.4277Z",
          "shell.execute_reply": "2024-03-28T07:19:56.480636Z"
        },
        "trusted": true,
        "id": "ZseZrnGgfjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean Average Power"
      ],
      "metadata": {
        "id": "jJ0anHXufjVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def abs_ave(data, output=False):\n",
        "    # Initialize an empty DataFrame to store the means for each channel\n",
        "    means_abs = pd.DataFrame(index=data.index)\n",
        "\n",
        "    # Iterate over each channel and calculate the mean across 'D1' to 'D5'\n",
        "    for channel in data.columns.get_level_values(0).unique():\n",
        "    # Calculate the mean for the current channel\n",
        "        means_abs[channel] = data[channel].abs().mean(axis = 1)\n",
        "\n",
        "    means_abs.columns = [f\"{col}_DT_mean_abs\" for col in means_abs.columns]\n",
        "\n",
        "    return means_abs\n",
        "\n",
        "example_wavelet_meanabs = abs_ave(example_wavelets, output=True)\n",
        "example_wavelet_meanabs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T07:36:45.956285Z",
          "iopub.execute_input": "2024-03-28T07:36:45.956617Z",
          "iopub.status.idle": "2024-03-28T07:36:46.014567Z",
          "shell.execute_reply.started": "2024-03-28T07:36:45.956589Z",
          "shell.execute_reply": "2024-03-28T07:36:46.013199Z"
        },
        "trusted": true,
        "id": "1R3SZ6bafjVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STD"
      ],
      "metadata": {
        "id": "-QuVMzRHfjVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def std_val(data, output=False):\n",
        "    # Initialize an empty DataFrame to store the means for each channel\n",
        "    means_abs = pd.DataFrame(index=data.index)\n",
        "\n",
        "    # Iterate over each channel and calculate the mean across 'D1' to 'D5'\n",
        "    for channel in data.columns.get_level_values(0).unique():\n",
        "    # Calculate the mean for the current channel\n",
        "        means_abs[channel] = data[channel].std(axis = 1)\n",
        "\n",
        "    means_abs.columns = [f\"{col}_DT_mean_abs\" for col in means_abs.columns]\n",
        "\n",
        "    return means_abs\n",
        "\n",
        "example_wavelet_std = std_val(example_wavelets, output=True)\n",
        "example_wavelet_std"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T07:36:53.598519Z",
          "iopub.execute_input": "2024-03-28T07:36:53.598903Z",
          "iopub.status.idle": "2024-03-28T07:36:53.659494Z",
          "shell.execute_reply.started": "2024-03-28T07:36:53.59887Z",
          "shell.execute_reply": "2024-03-28T07:36:53.657954Z"
        },
        "trusted": true,
        "id": "R0CvnYp0fjVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ratio_channels(epoch_data):\n",
        "\n",
        "  decimation_levels = list(epoch_data.index)\n",
        "\n",
        "  ratio_data=pd.Series()\n",
        "  for level_no in range(0, len(decimation_levels)):\n",
        "    # for the first decimation\n",
        "    if level_no == 0:\n",
        "      ratio_data[decimation_levels[level_no]] = \\\n",
        "      epoch_data.loc[decimation_levels[level_no]]/epoch_data.loc[decimation_levels[level_no+1]]\n",
        "    #for the last decimation\n",
        "    elif level_no == len(decimation_levels)-1:\n",
        "      ratio_data[decimation_levels[level_no]] = \\\n",
        "      epoch_data.loc[decimation_levels[level_no]]/epoch_data.loc[decimation_levels[level_no-1]]\n",
        "    else:\n",
        "      before = epoch_data.loc[decimation_levels[level_no-1]]\n",
        "      after = epoch_data.loc[decimation_levels[level_no+1]]\n",
        "      mean_data = (before+after)/2\n",
        "\n",
        "      ratio_data[decimation_levels[level_no]] = \\\n",
        "      epoch_data.loc[decimation_levels[level_no]]/mean_data\n",
        "\n",
        "  #name the index column\n",
        "  ratio_data.index.name = 'features'\n",
        "\n",
        "  return ratio_data\n",
        "\n",
        "# get the ratio\n",
        "example_ratio_data = example_wavelets.mean().unstack('channel').apply(ratio_channels)\n",
        "example_ratio_data = reformat(example_ratio_data, 'Ratio_Mean_')\n",
        "display(example_ratio_data.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T05:58:06.387201Z",
          "iopub.execute_input": "2024-03-28T05:58:06.387513Z",
          "iopub.status.idle": "2024-03-28T05:58:06.475781Z",
          "shell.execute_reply.started": "2024-03-28T05:58:06.38749Z",
          "shell.execute_reply": "2024-03-28T05:58:06.474602Z"
        },
        "trusted": true,
        "id": "hMkigXfVfjVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szu-6C0qfjVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cFHIRNH3fjVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D2LFuZ_JfjVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, MaxPooling1D, Flatten, Dense, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_cnn_rnn_model(input_shape=(310, 19), num_classes=2):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # CNN Module (DenseNet-BC architecture)\n",
        "    x = inputs\n",
        "    growth_rate = 32\n",
        "    for i in range(7):\n",
        "        x = dense_block(x, growth_rate, layers=4)\n",
        "        if i != 6:\n",
        "            x = transition_block(x)\n",
        "\n",
        "    # RNN Module (Bidirectional LSTM)\n",
        "    x = Bidirectional(LSTM(units=8, return_sequences=True))(x)\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(16, activation='relu')(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "def dense_block(x, growth_rate, layers=4):\n",
        "    for _ in range(layers):\n",
        "        x = conv_block(x, growth_rate)\n",
        "    return x\n",
        "\n",
        "def conv_block(x, growth_rate):\n",
        "    x1 = BatchNormalization()(x)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv1D(filters=4*growth_rate, kernel_size=1, padding='same')(x1)\n",
        "\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation('relu')(x1)\n",
        "    x1 = Conv1D(filters=growth_rate, kernel_size=3, padding='same')(x1)\n",
        "\n",
        "    x = tf.keras.layers.concatenate([x, x1], axis=-1)\n",
        "    return x\n",
        "\n",
        "def transition_block(x):\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv1D(filters=int(x.shape[-1])//2, kernel_size=1, padding='same')(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    return x\n",
        "\n",
        "# Build the model\n",
        "model = build_cnn_rnn_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-28T02:43:38.683612Z",
          "iopub.status.idle": "2024-03-28T02:43:38.683861Z",
          "shell.execute_reply.started": "2024-03-28T02:43:38.683736Z",
          "shell.execute_reply": "2024-03-28T02:43:38.683747Z"
        },
        "trusted": true,
        "id": "_zyWaYSbfjVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define functions to create the CNN and RNN modules separately.\n",
        "\n",
        "The build_cnn_rnn_model function integrates both modules into a single model.\n",
        "\n",
        "The **CNN** module consists of **7 dense blocks, each containing 4 convolutional layers** with a **growth rate of 32.**\n",
        "\n",
        "Between dense blocks, transition blocks are used to reduce the number of feature maps and downsample the input.\n",
        "\n",
        "After the CNN module, **a bidirectional LSTM layer** is added to capture long-term dependencies.\n",
        "\n",
        "Finally, a fully connected layer and an output layer are added for classification.\n",
        "\n",
        "We then build the model and print its summary to examine the architecture."
      ],
      "metadata": {
        "id": "m9TK9eTYfjVb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VRN8Tfk8fjVb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}